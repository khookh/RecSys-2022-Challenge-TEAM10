{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5ec86f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/25 08:47:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/05/25 08:47:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/05/25 08:47:17 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/05/25 08:47:17 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/05/25 08:47:17 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import warnings\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import sys\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "\n",
    "# launch this cell if you have issues on windows with py4j (think about updating your PATH)\n",
    "\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS']= \"notebook\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "\n",
    "# starts a spark session from notebook\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] =\"--conf spark.driver.memory=4g  pyspark-shell\"\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"feature_selection\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f14d49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_sessions_engineered = spark.read.csv('../Data/session_engineered_features.txt',header=False,\n",
    "                                          inferSchema=True)\n",
    "\n",
    "train_purchases = spark.read.load('../Data/train_purchases.csv', \n",
    "                          format='com.databricks.spark.csv', \n",
    "                          header='true', \n",
    "                          inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2abbb085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/25 08:47:26 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 38)\n",
      "[[312.   0. 163. ...   0.   0.   0.]\n",
      " [  3.   0.   2. ...   1.   3.   0.]\n",
      " [  5.   4.   4. ...   3.   1.   2.]\n",
      " ...\n",
      " [  0.   0.   0. ...   0.   0.   0.]\n",
      " [  0.   0.   0. ...   0.   0.   0.]\n",
      " [  0.   0.   0. ...   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "# sort by session\n",
    "X = train_sessions_engineered.orderBy('_c0') \n",
    "X = X.drop('_c0')\n",
    "X.take(10)\n",
    "\n",
    "X_np = np.array(X.collect())\n",
    "X_np_split = X_np[:10000]\n",
    "print(X_np_split.shape)\n",
    "t_X = np.transpose(X_np_split)\n",
    "n_total_features = t_X.shape[0]\n",
    "print(t_X)\n",
    "# we want the nb partition to be between 2 or 3 times more than the number of core in our computer\n",
    "Nb_partition=10\n",
    "X_RDD = sc.parallelize(t_X,Nb_partition)\n",
    "\n",
    "\n",
    "# Counting the number of rows will allow to implicitly cache the data\n",
    "#print(X_RDD.count())\n",
    "#X_RDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c8462e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15085 18626 24911 ... 21630 16962 16631]\n"
     ]
    }
   ],
   "source": [
    "train_purchases_reformated = train_purchases.drop('date').withColumnRenamed('item_id', 'item_id_purchased')\n",
    "\n",
    "Y_order_by_session_id = train_purchases_reformated.drop('session_id')\n",
    "\n",
    "#Y_order_by_session_id.take(10)\n",
    "Y_numpy = np.array(Y_order_by_session_id.collect())\n",
    "Y_numpy = Y_numpy.flatten()\n",
    "print(Y_numpy)\n",
    "Y_numpy_split = Y_numpy[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aadab93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.count())\n",
    "len(X_np_split) == len(Y_numpy_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c77a9d3",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "After the feature engineering, we could have a lot of features which are not really worth to give to the predicting model. Considering this problem, we want to use some feature selection algorithms to take the feature which are the most interesting to the model.\n",
    "\n",
    "We were asked to implement two scalable feature selection algorithms, a ranking algorithm and a forward feature selection.\n",
    "\n",
    "We could be interested in Minimum-redundancy-maximum-relevance (mRMR) feature selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30368934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef generate_dataset(n_samples=100, n_informative=1, n_noisy=2, n_redundant=1, random_seed=0):\\n    \"\"\"\\n    generate a dataset to test\\n    \"\"\"\\n    # Set random seed\\n    np.random.seed(random_seed)\\n    \\n    # Use sklearn.datasets.make_regression to generate an artificial dataset where the output y \\n    # is correlated with a subset of of the input features\\n    X, Y = sklearn.datasets.make_classification(n_samples=n_samples, \\n                                            n_features=n_informative+n_noisy, \\n                                            n_informative=n_informative)\\n    \\n    # Create a random mixing matrix for generating redundant features from informative ones\\n    mixing_matrix = np.random.random((n_informative, n_redundant))\\n    \\n    # Create redundant features by taking random linear combinations of informative features\\n    redundant_features = np.dot(X[:,0:n_informative], mixing_matrix)\\n    \\n    # Add redundant features to the input data\\n    X = np.concatenate((X, redundant_features), axis=1)\\n    \\n    # Return input data X, output data Y\\n    return X, Y\\n\\n\\n# Let us generate the dataset\\nN = 1000\\nn_informative = 100\\nn_noisy = 100\\nn_redundant = 100\\n\\nX, Y = generate_dataset(n_samples=N, \\n                        n_informative=n_informative, \\n                        n_noisy=n_noisy, \\n                        n_redundant=n_redundant)\\n\\nt_X = np.transpose(X)\\n\\nB=3\\nX_RDD=sc.parallelize(t_X,B).cache()\\n\\n# Counting the number of rows will allow to implicitly cache the data\\nX_RDD.count()\\nX_RDD.take(10)\\n\\nprint(type(Y))'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def generate_dataset(n_samples=100, n_informative=1, n_noisy=2, n_redundant=1, random_seed=0):\n",
    "    \"\"\"\n",
    "    generate a dataset to test\n",
    "    \"\"\"\n",
    "    # Set random seed\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    # Use sklearn.datasets.make_regression to generate an artificial dataset where the output y \n",
    "    # is correlated with a subset of of the input features\n",
    "    X, Y = sklearn.datasets.make_classification(n_samples=n_samples, \n",
    "                                            n_features=n_informative+n_noisy, \n",
    "                                            n_informative=n_informative)\n",
    "    \n",
    "    # Create a random mixing matrix for generating redundant features from informative ones\n",
    "    mixing_matrix = np.random.random((n_informative, n_redundant))\n",
    "    \n",
    "    # Create redundant features by taking random linear combinations of informative features\n",
    "    redundant_features = np.dot(X[:,0:n_informative], mixing_matrix)\n",
    "    \n",
    "    # Add redundant features to the input data\n",
    "    X = np.concatenate((X, redundant_features), axis=1)\n",
    "    \n",
    "    # Return input data X, output data Y\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "# Let us generate the dataset\n",
    "N = 1000\n",
    "n_informative = 100\n",
    "n_noisy = 100\n",
    "n_redundant = 100\n",
    "\n",
    "X, Y = generate_dataset(n_samples=N, \n",
    "                        n_informative=n_informative, \n",
    "                        n_noisy=n_noisy, \n",
    "                        n_redundant=n_redundant)\n",
    "\n",
    "t_X = np.transpose(X)\n",
    "\n",
    "B=3\n",
    "X_RDD=sc.parallelize(t_X,B).cache()\n",
    "\n",
    "# Counting the number of rows will allow to implicitly cache the data\n",
    "X_RDD.count()\n",
    "X_RDD.take(10)\n",
    "\n",
    "print(type(Y))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "905cec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_mrmr(x, y):\n",
    "    \"\"\"\n",
    "    return the correlation value between two variable in absolute value\n",
    "    \"\"\"\n",
    "\n",
    "    return np.abs(scipy.stats.pearsonr(x, y)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caf9570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mrmr_score_spark(x,selected_features):\n",
    "    \"\"\"\n",
    "    x : the feature to evaluate to add into the model\n",
    "    y : output value\n",
    "    selected_features : the features already selected\n",
    "    return the score for x with the rest of selected variables\n",
    "    \"\"\"\n",
    "    \n",
    "    y = broadcast_Y.value\n",
    "    # Get correlation score between feature x and output y (relevance)\n",
    "    score_x_y_s = get_score_mrmr(x, y)\n",
    "    \n",
    "    \n",
    "    nb_selected_features = selected_features.shape[0]\n",
    "    # If some features have already been selected\n",
    "    if nb_selected_features > 0:\n",
    "        \n",
    "        # Get corrrelation scores between x and each feature already selected (redundancy)\n",
    "        score_features_x_s = np.zeros(nb_selected_features, dtype=float)\n",
    "        \n",
    "        for j in range(nb_selected_features):\n",
    "            \n",
    "            score_x_s_j = get_score_mrmr(x, selected_features[j,:])\n",
    "            \n",
    "            # if score is nan considering that we want to calculate the mean\n",
    "            # we transform it in 0 ?\n",
    "            if np.isnan(score_x_s_j):\n",
    "                score_x_s_j=0\n",
    "            \n",
    "                \n",
    "            score_features_x_s[j] = score_x_s_j\n",
    "        \n",
    "        print(score_x_s_j)\n",
    "                \n",
    "        # Final score is relevance to output feature - average redundancy with already selected features\n",
    "        score_x_y_s = score_x_y_s - np.mean(score_features_x_s)\n",
    "        \n",
    "    return score_x_y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ded7f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrmr_spark(n_total_features, K, sc, X_RDD):\n",
    "    \"\"\"\n",
    "    n_total_features : number of total features\n",
    "    K : number of feature to select\n",
    "    sc : spark context\n",
    "    X_RDD : RDD of the variable X\n",
    "    Y: Output data\n",
    "    \n",
    "    return the indice of selected features and time execution using mrmr\n",
    "    \"\"\"\n",
    "    time_execution = []\n",
    "    remaining_features_indices = list(range(n_total_features))\n",
    "    selected_features_indices = []\n",
    "    \n",
    "\n",
    "    for k in range(K):\n",
    "        print(\"Step: \"+str(k))\n",
    "    \n",
    "        start_time=time.time()\n",
    "        # Get the subset of selected features values, and cast as an array\n",
    "        selected_features = X_RDD.zipWithIndex().filter(lambda x: x[1] in selected_features_indices).map(lambda x: x[0]).collect()\n",
    "        selected_features = np.array(selected_features)\n",
    "        print(selected_features)\n",
    "    \n",
    "        # mRMR scores are computed by first filtering `t_X` to remove already selected features, and then mapping \n",
    "        # each remaining feature using the `get_mrmr_score_spark` function\n",
    "        scores = X_RDD.zipWithIndex().filter(lambda x: x[1] in remaining_features_indices).map(lambda x:get_mrmr_score_spark(x[0],selected_features)).collect()\n",
    "    \n",
    "        # Once all mRMR scores are computed, the index of the feature with the highest score is selected\n",
    "        scores = np.array(scores)\n",
    "        \n",
    "    \n",
    "        index_max_score_features = np.argmax(scores)\n",
    "    \n",
    "        selected_features_indices.append(remaining_features_indices[index_max_score_features])\n",
    "    \n",
    "        del(remaining_features_indices[index_max_score_features])\n",
    "    \n",
    "        print(time.time()-start_time)\n",
    "        time_execution.append(time.time()-start_time)\n",
    "        \n",
    "    return selected_features_indices, time_execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86d803b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guest/anaconda3/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1576128005981445\n",
      "Step: 1\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "/home/guest/anaconda3/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "/home/guest/anaconda3/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "/home/guest/anaconda3/lib/python3.9/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6671199798583984\n",
      "Step: 2\n",
      "[[2020. 2020. 2020. ... 2020. 2020. 2021.]\n",
      " [   0.    0.    0. ...    0.    0.    0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5938024520874023\n",
      "Step: 3\n",
      "[[ 312.    0.  163. ...    0.    0.    0.]\n",
      " [2020. 2020. 2020. ... 2020. 2020. 2021.]\n",
      " [   0.    0.    0. ...    0.    0.    0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5705294609069824\n",
      "Step: 4\n",
      "[[ 312.    0.  163. ...    0.    0.    0.]\n",
      " [2020. 2020. 2020. ... 2020. 2020. 2021.]\n",
      " [   0.    0.    0. ...    0.    0.    0.]\n",
      " [   0.    0.    0. ...    0.    0.    0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48273682594299316\n",
      "Step: 5\n",
      "[[ 312.    0.  163. ...    0.    0.    0.]\n",
      " [2020. 2020. 2020. ... 2020. 2020. 2021.]\n",
      " [   0.    0.    0. ...    0.    0.    0.]\n",
      " [   0.    0.    0. ...    0.    0.    0.]\n",
      " [   0.    0.    0. ...    0.    0.    0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.638981819152832\n",
      "Step: 6\n",
      "[[ 312.    0.  163. ...    0.    0.    0.]\n",
      " [2020. 2020. 2020. ... 2020. 2020. 2021.]\n",
      " [   0.    0.    0. ...    0.    0.    0.]\n",
      " [   0.    0.    0. ...    0.    0.    0.]\n",
      " [   0.    0.    0. ...    0.    0.    0.]\n",
      " [   0.    0.    0. ...    0.    0.    0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "00\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5496511459350586\n",
      "Step: 7\n",
      "[[ 312.    0.  163. ...    0.    0.    0.]\n",
      " [2020. 2020. 2020. ... 2020. 2020. 2021.]\n",
      " [   0.    0.    0. ...    0.    0.    0.]\n",
      " ...\n",
      " [   0.    0.    0. ...    0.    0.    0.]\n",
      " [   0.    0.    0. ...    0.    0.    0.]\n",
      " [   0.    0.    0. ...    0.    0.    0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5582265853881836\n",
      "Step: 8\n",
      "[[ 312.    0.  163. ...    0.    0.    0.]\n",
      " [2020. 2020. 2020. ... 2020. 2020. 2021.]\n",
      " [   0.    0.    0. ...    0.    0.    0.]\n",
      " ...\n",
      " [   0.    0.    0. ...    0.    0.    0.]\n",
      " [   0.    0.    0. ...    0.    0.    0.]\n",
      " [   0.    0.    0. ...    0.    0.    0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5628674030303955\n",
      "Step: 9\n",
      "[[  312.     0.   163. ...     0.     0.     0.]\n",
      " [ 2020.  2020.  2020. ...  2020.  2020.  2021.]\n",
      " [ 9655. 15654. 18316. ... 23456. 15624. 27244.]\n",
      " ...\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "00\n",
      "\n",
      "00\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5790812969207764\n",
      "Step: 10\n",
      "[[  312.     0.   163. ...     0.     0.     0.]\n",
      " [ 2020.  2020.  2020. ...  2020.  2020.  2021.]\n",
      " [ 9655. 15654. 18316. ... 23456. 15624. 27244.]\n",
      " ...\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "00\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5120329856872559\n",
      "Step: 11\n",
      "[[  312.     0.   163. ...     0.     0.     0.]\n",
      " [ 2020.  2020.  2020. ...  2020.  2020.  2021.]\n",
      " [ 9655. 15654. 18316. ... 23456. 15624. 27244.]\n",
      " ...\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "00\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5649549961090088\n",
      "Step: 12\n",
      "[[  312.     0.   163. ...     0.     0.     0.]\n",
      " [ 2020.  2020.  2020. ...  2020.  2020.  2021.]\n",
      " [ 9655. 15654. 18316. ... 23456. 15624. 27244.]\n",
      " ...\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "00\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "00\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5364117622375488\n",
      "Step: 13\n",
      "[[  312.     0.   163. ...     0.     0.     0.]\n",
      " [ 2020.  2020.  2020. ...  2020.  2020.  2021.]\n",
      " [ 9655. 15654. 18316. ... 23456. 15624. 27244.]\n",
      " ...\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/25 08:48:07 WARN DAGScheduler: Broadcasting large task binary with size 1024.2 KiB\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "00\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "00\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.553333044052124\n",
      "Step: 14\n",
      "[[  312.     0.   163. ...     0.     0.     0.]\n",
      " [ 2020.  2020.  2020. ...  2020.  2020.  2021.]\n",
      " [ 9655. 15654. 18316. ... 23456. 15624. 27244.]\n",
      " ...\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5930342674255371\n",
      "Step: 15\n",
      "[[  312.     0.   163. ...     0.     0.     0.]\n",
      " [ 2020.  2020.  2020. ...  2020.  2020.  2021.]\n",
      " [ 9655. 15654. 18316. ... 23456. 15624. 27244.]\n",
      " ...\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55753493309021\n",
      "Step: 16\n",
      "[[  312.     0.   163. ...     0.     0.     0.]\n",
      " [ 2020.  2020.  2020. ...  2020.  2020.  2021.]\n",
      " [ 9655. 15654. 18316. ... 23456. 15624. 27244.]\n",
      " ...\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "00\n",
      "\n",
      "00\n",
      "\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5732262134552002\n",
      "Step: 17\n",
      "[[  312.     0.   163. ...     0.     0.     0.]\n",
      " [ 2020.  2020.  2020. ...  2020.  2020.  2021.]\n",
      " [ 9655. 15654. 18316. ... 23456. 15624. 27244.]\n",
      " ...\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "00\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5731711387634277\n",
      "Step: 18\n",
      "[[  312.     0.   163. ...     0.     0.     0.]\n",
      " [ 2020.  2020.  2020. ...  2020.  2020.  2021.]\n",
      " [ 9655. 15654. 18316. ... 23456. 15624. 27244.]\n",
      " ...\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "00\n",
      "\n",
      "0\n",
      "00\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "00\n",
      "\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5450198650360107\n",
      "Step: 19\n",
      "[[  312.     0.   163. ...     0.     0.     0.]\n",
      " [ 2020.  2020.  2020. ...  2020.  2020.  2021.]\n",
      " [ 9655. 15654. 18316. ... 23456. 15624. 27244.]\n",
      " ...\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]\n",
      " [    0.     0.     0. ...     0.     0.     0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "00\n",
      "\n",
      "00\n",
      "\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6271693706512451\n"
     ]
    }
   ],
   "source": [
    "broadcast_Y = sc.broadcast(Y_numpy_split)\n",
    "selected_features_indices, execution_time = mrmr_spark(n_total_features, 20, sc,X_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbc4fd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36, 4, 0, 34, 17, 35, 18, 32, 5, 33, 16, 31, 21, 19, 28, 26, 30, 14, 23, 13]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_indices\n",
    "#selected_features = X_RDD.zipWithIndex().filter(lambda x: x[1] in selected_features_indices).map(lambda x: x[0]).collect()\n",
    "\n",
    "#print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd2f0e8",
   "metadata": {},
   "source": [
    "Then, we will look a the forward feature Selection by training on a decision tree with every feature and add the features which get the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f884d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def fit_get_score(x,selected_features):\n",
    "    \"\"\"\n",
    "    train an model to get the score with the addition of a specified x feature\n",
    "    \"\"\"    \n",
    "    \n",
    "    y = broadcast_Y.value\n",
    "    n_selected_features = selected_features.shape[0]\n",
    "    \n",
    "    if n_selected_features>0:\n",
    "        # need to merge x and the already selected features\n",
    "        x = np.vstack((selected_features,x))\n",
    "        x = x.transpose()\n",
    "    else:\n",
    "        x = x.reshape(-1, 1)\n",
    "        \n",
    "    \n",
    "    #split data\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y, test_size= 0.3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # train on training data\n",
    "    model = tree.DecisionTreeClassifier()\n",
    "    model = model.fit(x_train,y_train)\n",
    "    \n",
    "    print(x_test.shape)\n",
    "    \n",
    "    # get score on testing set\n",
    "    return model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "035c9467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_feature_selection(n_total_features, K, sc, X_RDD):\n",
    "    \"\"\"\n",
    "    n_total_features : number of total features\n",
    "    K : number of feature to select\n",
    "    sc : spark context\n",
    "    X_RDD : RDD of the variable X\n",
    "    Y: Output data\n",
    "    \n",
    "    return the indice of selected features and time execution\n",
    "    by using a decision tree as model to calculate the score\n",
    "    \"\"\"\n",
    "    time_execution = []\n",
    "    \n",
    "    remaining_features_indices = list(range(n_total_features))\n",
    "    selected_features_indices = []\n",
    "    \n",
    "    for k in range(K):\n",
    "        print(\"Step: \"+str(k))\n",
    "    \n",
    "        start_time=time.time()\n",
    "\n",
    "        # Get the subset of selected features values, and cast as an array\n",
    "        selected_features = X_RDD.zipWithIndex().filter(lambda x: x[1] in selected_features_indices).map(lambda x: x[0]).collect()\n",
    "        selected_features = np.array(selected_features)\n",
    "        \n",
    "    \n",
    "        #  scores for a certain model are computed by first filtering `t_X` to remove already selected features, and then mapping \n",
    "        # each remaining feature using the `fit_get_score` function\n",
    "        scores = X_RDD.zipWithIndex().filter(lambda x: x[1] in remaining_features_indices).map(lambda x:fit_get_score(x[0],selected_features)).collect()\n",
    "    \n",
    "        # Once all scores are computed, the index of the feature with the highest value is chosen\n",
    "        scores = np.array(scores)\n",
    "        \n",
    "        print(\"best_score :\", np.max(scores))\n",
    "    \n",
    "        index_max_score_features = np.argmax(scores)\n",
    "    \n",
    "        selected_features_indices.append(remaining_features_indices[index_max_score_features])\n",
    "    \n",
    "        del(remaining_features_indices[index_max_score_features])\n",
    "    \n",
    "        print(time.time()-start_time)\n",
    "        time_execution.append(time.time()-start_time)\n",
    "        \n",
    "    return selected_features_indices, time_execution\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f153a681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(3000, 1):>                                                        (0 + 4) / 10]\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1):===========>                                             (2 + 4) / 10]\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1):======================>                                  (4 + 4) / 10]\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1):============================>                            (5 + 4) / 10]\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1):=============================================>           (8 + 2) / 10]\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1):===================================================>     (9 + 1) / 10]\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score : 0.019\n",
      "3.212231159210205\n",
      "Step: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(3000, 2):>                                                        (0 + 4) / 10]\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2):=====>                                                   (1 + 4) / 10]\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2):===========>                                             (2 + 4) / 10]\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2):=================>                                       (3 + 4) / 10]\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2):============================>                            (5 + 4) / 10]\n",
      "(3000, 2):==================================>                      (6 + 4) / 10]\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2):=======================================>                 (7 + 3) / 10]\n",
      "(3000, 2):=============================================>           (8 + 2) / 10]\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2):===================================================>     (9 + 1) / 10]\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score : 0.021\n",
      "14.44019103050232\n",
      "Step: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(3000, 3):>                                                        (0 + 4) / 10]\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3):=====>                                                   (1 + 4) / 10]\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3):===========>                                             (2 + 4) / 10]\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3):=================>                                       (3 + 4) / 10]\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3):======================>                                  (4 + 4) / 10]\n",
      "(3000, 3):============================>                            (5 + 4) / 10]\n",
      "(3000, 3):==================================>                      (6 + 4) / 10]\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3):=======================================>                 (7 + 3) / 10]\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3):=============================================>           (8 + 2) / 10]\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score : 0.020666666666666667\n",
      "14.290701627731323\n",
      "Step: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(3000, 4):>                                                        (0 + 4) / 10]\n",
      "(3000, 4)\n",
      "(3000, 4)\n",
      "(3000, 4)\n",
      "(3000, 4)\n",
      "(3000, 4):=====>                                                   (1 + 4) / 10]\n",
      "(3000, 4)\n",
      "(3000, 4)\n",
      "(3000, 4)\n",
      "(3000, 4)\n",
      "(3000, 4):===========>                                             (2 + 4) / 10]\n",
      "(3000, 4)\n",
      "(3000, 4)\n",
      "(3000, 4)\n",
      "(3000, 4)\n",
      "(3000, 4):=================>                                       (3 + 4) / 10]\n",
      "(3000, 4)\n",
      "(3000, 4)\n",
      "(3000, 4)\n",
      "(3000, 4):======================>                                  (4 + 4) / 10]\n",
      "(3000, 4):============================>                            (5 + 4) / 10]\n",
      "(3000, 4):==================================>                      (6 + 4) / 10]\n",
      "(3000, 4)\n",
      "(3000, 4)\n",
      "(3000, 4)\n",
      "(3000, 4)\n",
      "(3000, 4)\n",
      "(3000, 4):=======================================>                 (7 + 3) / 10]\n",
      "(3000, 4)\n",
      "(3000, 4)\n",
      "(3000, 4)\n",
      "(3000, 4):=============================================>           (8 + 2) / 10]\n",
      "(3000, 4):===================================================>     (9 + 1) / 10]\n",
      "(3000, 4)\n",
      "(3000, 4)\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score : 0.021\n",
      "15.035150289535522\n",
      "Step: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(3000, 5)0:>                                                       (0 + 4) / 10]\n",
      "(3000, 5)\n",
      "(3000, 5)\n",
      "(3000, 5)\n",
      "(3000, 5)\n",
      "(3000, 5)0:=====>                                                  (1 + 4) / 10]\n",
      "(3000, 5)\n",
      "(3000, 5)\n",
      "(3000, 5)\n",
      "(3000, 5)\n",
      "(3000, 5)\n",
      "(3000, 5)0:===========>                                            (2 + 4) / 10]\n",
      "(3000, 5)\n",
      "(3000, 5)\n",
      "(3000, 5)\n",
      "(3000, 5)\n",
      "(3000, 5)0:================>                                       (3 + 4) / 10]\n",
      "(3000, 5)\n",
      "(3000, 5)0:======================>                                 (4 + 4) / 10]\n",
      "(3000, 5)\n",
      "(3000, 5)0:============================>                           (5 + 4) / 10]\n",
      "(3000, 5)\n",
      "(3000, 5)0:=================================>                      (6 + 4) / 10]\n",
      "(3000, 5)\n",
      "(3000, 5)\n",
      "(3000, 5)\n",
      "(3000, 5)0:=======================================>                (7 + 3) / 10]\n",
      "(3000, 5)\n",
      "(3000, 5)\n",
      "(3000, 5)\n",
      "(3000, 5)0:============================================>           (8 + 2) / 10]\n",
      "(3000, 5)\n",
      "(3000, 5)\n",
      "[Stage 100:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score : 0.020666666666666667\n",
      "14.24113655090332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(3000, 5)\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5, 28, 22, 36, 14]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_indices_forward, execution_time_forward = forward_feature_selection(n_total_features, 5, sc,X_RDD)\n",
    "selected_features_indices_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "864e2f7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def forward_feature_selection_diff(n_total_features, inc_accuracy, sc, X_RDD):\n",
    "    \"\"\"\n",
    "    n_total_features : number of total features\n",
    "    inc_accuracy : increase of accuracy needed to continue the algorithm\n",
    "    sc : spark context\n",
    "    X_RDD : RDD of the variable X\n",
    "    Y: Output data\n",
    "    \n",
    "    return the indice of selected features and time execution\n",
    "    by using a decision tree as model to calculate the score\n",
    "    \"\"\"\n",
    "    time_execution = []\n",
    "    \n",
    "    remaining_features_indices = list(range(n_total_features))\n",
    "    selected_features_indices = []\n",
    "    \n",
    "    last_best_score = 0\n",
    "    diff_accuracy = 1\n",
    "    k = 0\n",
    "    while diff_accuracy > inc_accuracy:\n",
    "        print(\"Step: \"+str(k))\n",
    "    \n",
    "        start_time=time.time()\n",
    "\n",
    "        # Get the subset of selected features values, and cast as an array\n",
    "        selected_features = X_RDD.zipWithIndex().filter(lambda x: x[1] in selected_features_indices).map(lambda x: x[0]).collect()\n",
    "        selected_features = np.array(selected_features)\n",
    "        \n",
    "    \n",
    "        #  scores for a certain model are computed by first filtering `t_X` to remove already selected features, and then mapping \n",
    "        # each remaining feature using the `fit_get_score` function\n",
    "        scores = X_RDD.zipWithIndex().filter(lambda x: x[1] in remaining_features_indices).map(lambda x:fit_get_score(x[0],selected_features)).collect()\n",
    "    \n",
    "        # Once all scores are computed, the index of the feature with the highest value is chosen\n",
    "        scores = np.array(scores)\n",
    "        \n",
    "        # compute the difference between last result and new result\n",
    "        best_score = np.max(scores)\n",
    "        diff_accuracy = best_score - last_best_score\n",
    "        \n",
    "        \n",
    "        print(\"best_accuracy:\", best_score)\n",
    "        \n",
    "        if best_score > last_best_score:\n",
    "        \n",
    "            index_max_score_features = np.argmax(scores)\n",
    "    \n",
    "            selected_features_indices.append(remaining_features_indices[index_max_score_features])\n",
    "    \n",
    "            del(remaining_features_indices[index_max_score_features])\n",
    "        \n",
    "        last_best_score = best_score\n",
    "        print(time.time()-start_time)\n",
    "        time_execution.append(time.time()-start_time)\n",
    "        \n",
    "        k += 1\n",
    "        \n",
    "    return selected_features_indices, time_execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "410f759e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)4:>                                                       (0 + 4) / 10]\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)4:===========>                                            (2 + 4) / 10]\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)4:======================>                                 (4 + 4) / 10]\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)4:============================>                           (5 + 4) / 10]\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)\n",
      "(3000, 1)4:============================================>           (8 + 2) / 10]\n",
      "(3000, 1)\n",
      "(3000, 1)4:==================================================>     (9 + 1) / 10]\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_accuracy: 0.015666666666666666\n",
      "2.7608773708343506\n",
      "Step: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(3000, 2)8:>                                                       (0 + 4) / 10]\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)8:=====>                                                  (1 + 4) / 10]\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)8:===========>                                            (2 + 4) / 10]\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)8:================>                                       (3 + 4) / 10]\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)8:======================>                                 (4 + 4) / 10]\n",
      "(3000, 2)8:============================>                           (5 + 4) / 10]\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)8:=================================>                      (6 + 4) / 10]\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)8:=======================================>                (7 + 3) / 10]\n",
      "(3000, 2)\n",
      "(3000, 2)8:============================================>           (8 + 2) / 10]\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)\n",
      "(3000, 2)8:==================================================>     (9 + 1) / 10]\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_accuracy: 0.021\n",
      "14.777044534683228\n",
      "Step: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(3000, 3)2:>                                                       (0 + 4) / 10]\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)2:=====>                                                  (1 + 4) / 10]\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)2:===========>                                            (2 + 4) / 10]\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)2:================>                                       (3 + 4) / 10]\n",
      "(3000, 3)2:======================>                                 (4 + 4) / 10]\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)2:============================>                           (5 + 4) / 10]\n",
      "(3000, 3)\n",
      "(3000, 3)2:=================================>                      (6 + 4) / 10]\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)2:=======================================>                (7 + 3) / 10]\n",
      "(3000, 3)\n",
      "(3000, 3)\n",
      "(3000, 3)2:============================================>           (8 + 2) / 10]\n",
      "(3000, 3)\n",
      "(3000, 3)2:==================================================>     (9 + 1) / 10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_accuracy: 0.020666666666666667\n",
      "14.918395042419434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(3000, 3)\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5, 25]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_indices_forward_diff, execution_time_forward_diff = forward_feature_selection_diff(n_total_features, 0.0001, sc,X_RDD)\n",
    "selected_features_indices_forward_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc1567b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
