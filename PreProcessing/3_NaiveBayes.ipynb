{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a70e1a36-77d5-438d-b431-f871090c0153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/26 17:16:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/05/26 17:16:33 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/05/26 17:16:33 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import warnings\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import sys\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "\n",
    "# launch this cell if you have issues on windows with py4j (think about updating your PATH)\n",
    "\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS']= \"notebook\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "\n",
    "# starts a spark session from notebook\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] =\"--conf spark.driver.memory=4g  pyspark-shell\"\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"feature_selection\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "362919ae-93d3-4df7-b3ff-46a1ae092e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/26 17:16:41 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#train_sessions_engineered = spark.read.csv('../Data/session_engineered_features.csv',header=False,\n",
    "#                                          inferSchema=True)\n",
    "train_sessions_engineered = spark.read.load('../Data/session_engineered_features.csv', \n",
    "                          format='com.databricks.spark.csv', \n",
    "                          header='true', \n",
    "                          inferSchema='true').cache()\n",
    "\n",
    "train_purchases = spark.read.load('../Data/train_purchases.csv', \n",
    "                          format='com.databricks.spark.csv', \n",
    "                          header='true', \n",
    "                          inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef2309c-ba03-4c89-a341-9e30c7056b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- session_id: integer (nullable = true)\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_purchases.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b20f6d44-3391-4a2e-b51c-d0c72cc713ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most_time_spent_on_item\n",
      "mean_time\n",
      "std_time\n"
     ]
    }
   ],
   "source": [
    "# BINING \n",
    "from pyspark.ml.feature import Bucketizer\n",
    "to_bin = ['session_time','most_time_spent_on_item','mean_time','std_time']#+ [str(i+1) for i in range(25)]\n",
    "for col in to_bin:\n",
    "    print(col)\n",
    "    column_values = train_sessions_engineered.select(col).collect()\n",
    "    splits_list = [0]\n",
    "    for i in range(10):\n",
    "        p = 10 * (i+1)\n",
    "        splits_list.append(np.percentile(column_values, p))\n",
    "    splits_list.append(float('Inf'))\n",
    "    bucketizer = Bucketizer(splits=list(np.unique(splits_list)),inputCol=col, outputCol=col+\"_binned\")\n",
    "    train_sessions_engineered = bucketizer.setHandleInvalid(\"keep\").transform(train_sessions_engineered)\n",
    "    train_sessions_engineered = train_sessions_engineered.drop(col)\n",
    "    train_sessions_engineered = train_sessions_engineered.withColumnRenamed(col+\"_binned\",col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f986b20-fd75-4d4e-8311-378ef400bb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(session_id=28560.0, season=3.0, day_period=2.0, month=8.0, year=0.0, item_most_time_spent=5.0, most_frequently_bought_for_time_spent=28.0, least_frequently_bought_for_time_spent=25.0, item_most_visited=-1.0, number_o_visit=-1.0, number_o_revisited_items=0.0, most_frequently_bought_for_most_revisited=5.0, first_item_visited=23.0, last_item_visited=26.0, normalized_features_vector=5.0, 1=4.0, 2=0.0, 3=0.0, 4=0.0, 5=0.0, 6=0.0, 7=0.0, 8=0.1666666716337204, 9=0.0, 10=0.0, 11=0.0, 12=0.0, 13=0.0, 14=0.0, 15=0.0, 16=0.0, 17=0.0, 18=0.0, 19=0.0, 20=0.8333333134651184, 21=0.0, 22=0.0, 23=0.0, 24=0.0, 25=0.0, _45=0.0, session_time=3.0, most_time_spent_on_item=3.0, mean_time=3.0, std_time=1.0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sessions_engineered.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5466537-6bfb-4ac7-87c4-057dfac6cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the dataframes on the session ids and drop useless columns\n",
    "train_df = train_sessions_engineered.join(train_purchases,train_sessions_engineered.session_id == train_purchases.session_id,\"inner\" ).cache()\n",
    "for col in ['session_id','date']:\n",
    "    train_df = train_df.drop(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83acd03c-2362-49cf-9de1-06e71d91dd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(season=1.0, day_period=2.0, month=3.0, year=1.0, item_most_time_spent=23.0, most_frequently_bought_for_time_spent=11.0, least_frequently_bought_for_time_spent=12.0, item_most_visited=-1.0, number_o_visit=-1.0, number_o_revisited_items=0.0, most_frequently_bought_for_most_revisited=5.0, first_item_visited=23.0, last_item_visited=23.0, normalized_features_vector=23.0, 1=2.0, 2=0.0, 3=0.0, 4=0.0, 5=0.0, 6=0.0, 7=0.0, 8=0.0, 9=0.0, 10=0.0, 11=0.0, 12=0.0, 13=0.0, 14=0.0, 15=0.0, 16=0.0, 17=1.0, 18=0.0, 19=0.0, 20=0.0, 21=0.0, 22=0.0, 23=0.0, 24=0.0, 25=0.0, _45=0.0, session_time=3.0, most_time_spent_on_item=5.0, mean_time=4.0, std_time=2.0, item_id=1640)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.take(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c66567ef-5eee-457c-8152-463bd098d2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_df.write.option(\"header\",True).csv('/PROJ/Data/data_processed_for_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71e118ce-9aaa-4eec-a5c5-b874821e1619",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/26 17:25:45 WARN CacheManager: Asked to cache already cached data.        \n"
     ]
    }
   ],
   "source": [
    "train_df = spark.read.load('/PROJ/Data/data_processed_for_model.csv', \n",
    "                          format='com.databricks.spark.csv', \n",
    "                          header='true', \n",
    "                          inferSchema='true').cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9a868b-5b99-44d3-baeb-1581d4ba557a",
   "metadata": {},
   "source": [
    "# NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40006836-ca52-49ce-899f-bb40ab3036d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "def if_p(row):\n",
    "    row_bis = []\n",
    "    for count,elem in enumerate(row):\n",
    "        if elem == -1:\n",
    "            row_bis.append(0)\n",
    "        else:\n",
    "            row_bis.append(elem)\n",
    "    return row_bis\n",
    "\n",
    "train_df = train_df.rdd.map(if_p)\n",
    "\n",
    "def labelData(data):\n",
    "    return data.map(lambda x: LabeledPoint(int(x[-1]), x[:-1]))\n",
    "\n",
    "training_data, testing_data = labelData(train_df).randomSplit([0.9, 0.1])\n",
    "\n",
    "model = NaiveBayes.train(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "007340d3-f58c-4988-b232-00863762cc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from pyspark.mllib.linalg import _convert_to_vector\n",
    "from pyspark import RDD\n",
    "\n",
    "# define custom predict function \n",
    "def custom_predict(model_bayes, x):\n",
    "    labels_ = model_bayes.labels\n",
    "    pi = model_bayes.pi\n",
    "    theta = model_bayes.theta\n",
    "    if isinstance(x, RDD):\n",
    "        return x.map(lambda v: custom_predict(model_bayes,v))\n",
    "    x = _convert_to_vector(x)\n",
    "    x = pi + x.dot(theta.transpose())\n",
    "    indices = np.argsort(x)[-100:]\n",
    "    top100 = labels_[indices]\n",
    "    return top100 #labels_[numpy.argmax(pi + x.dot(theta.transpose()))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b9fd8990-ece7-4c6c-bbf5-07c7b5fd4209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12690.0, 26139.0),\n",
       " (8290.0, 19821.0),\n",
       " (10338.0, 2173.0),\n",
       " (24429.0, 16867.0),\n",
       " (2927.0, 16627.0),\n",
       " (16365.0, 22419.0),\n",
       " (10223.0, 9371.0),\n",
       " (11208.0, 23510.0),\n",
       " (5339.0, 23785.0),\n",
       " (3522.0, 19818.0),\n",
       " (26977.0, 11681.0),\n",
       " (8622.0, 4917.0),\n",
       " (13767.0, 6182.0),\n",
       " (10338.0, 21499.0),\n",
       " (20281.0, 164.0),\n",
       " (21043.0, 20037.0),\n",
       " (12540.0, 15573.0),\n",
       " (158.0, 10997.0),\n",
       " (26977.0, 8861.0),\n",
       " (6355.0, 27315.0)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data.map(lambda p: (model.predict(p.features), p.label)).take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1245bdb9-c7f3-49af-9c72-7dac0508f31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24429.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(testing_data.take(4)[3].features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0d5fb1-d923-4db7-99a9-7e06d30db0be",
   "metadata": {},
   "source": [
    "# TOP 100 with bayes pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7608ed0e-5e2a-4256-ba67-1ef92ec18202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18581. 10896. 14457.  4981. 18432. 15862. 23019. 16326. 18992.  6237.\n",
      " 25420. 16462. 23571. 27051. 18031.   897.   527.  5977. 18214. 12606.\n",
      " 18832. 26977. 18665. 13403.  1043. 20152.  4598.  2458. 25736.   228.\n",
      "  6089. 14961.  8795. 17806.  4130.  4885. 22821.   375. 27658.  3722.\n",
      " 25287. 18218.  4131.  3037. 15342.  8585. 21420. 15838.  3273.  8684.\n",
      " 17375. 27872. 20247. 21257.  5350. 23252. 24803. 11284. 23793. 28101.\n",
      "  6129. 13683. 28030. 27773.  4940.  9849. 26662. 18594.  4179. 16844.\n",
      " 11186. 26454. 18375.  7594. 17659. 13914. 23212. 10163. 27822. 12158.\n",
      "  7977.  5276. 11917. 15067. 13564. 26555.  6818.  5833.  9494. 21587.\n",
      " 15870. 23700.  6361. 16924.  2158.  1172.  2674. 19310.  8119. 24429.]\n"
     ]
    }
   ],
   "source": [
    "top100 = custom_predict(model,testing_data.take(4)[3].features)\n",
    "print(top100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b5913aa-cd3b-495c-8eec-870061672faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_top100 = testing_data.map(lambda p: (p.label in custom_predict(model,p.features), p.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9856a87f-afea-4c9c-afad-d507f82537bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(False, 26139.0),\n",
       " (False, 19821.0),\n",
       " (False, 2173.0),\n",
       " (False, 16867.0),\n",
       " (True, 16627.0),\n",
       " (False, 22419.0),\n",
       " (False, 9371.0),\n",
       " (False, 23510.0),\n",
       " (False, 23785.0),\n",
       " (False, 19818.0)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_top100.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "00690f21-bb08-4994-8c8a-7c72955685cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(False, 172319), (True, 28251)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_top100.map(lambda x : (x[0],(1))).reduceByKey(lambda x,y : np.add(x,y)).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c4611a1b-3c89-4577-bc00-01b913484333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.array([1,2,3,4,5,6,7,8]) == 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "42f8780b-9a43-4c2e-a55d-04a47239fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(top_100,label):\n",
    "    if label in top_100:\n",
    "        return (np.where(np.array(top_100) == label)[0][0] + 1)/100\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c24f8f66-bfa4-41e4-9386-182b2915624a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08662377224908996"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data.map(lambda p: (score(custom_predict(model,p.features),p.label))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35eda9c-857a-47ac-811b-bbc2bb759456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
